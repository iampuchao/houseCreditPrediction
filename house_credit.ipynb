{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\n#print(os.listdir())\n#app_train = pd.read_csv(\"./application_train.csv\")\n#app_test = pd.read_csv(\"./application_test.csv\")\n# For kaggle\n#print(os.listdir(\"../input\"))\napp_train = pd.read_csv(\"../input/application_train.csv\")\napp_test = pd.read_csv(\"../input/application_test.csv\")\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "749e5cf35f166f6576cb206937cfc11bd9653c3c"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print (app_train.shape)\napp_train.head()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b5dd32ad21ab9664185e187a8dc76eb8f288ac3c",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "app_test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "18f4c8d7d67934125e2bbb4dc1f1b388d6462ed5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a80ae748ab6b0220b9c371485c99e183e5848a91",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "missing_values = missing_values_table(app_train)\nmissing_values.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ff25132d3e8f10edc3934db5416cd2b38050cc49",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "app_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)\napp_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "81dfae3c89f75bbeb27b4b98b138984d054d68f2",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nct = 0\nfor col in app_train:\n    if (app_train[col].dtype == 'object'):\n        if len(list(app_train[col].unique())) <= 2:\n            le.fit(app_train[col])\n        #print(list(app_trian[col].unique()))\n            app_train[col] = le.transform(app_train[col])\n            app_test[col] = le.transform(app_test[col])\n            ct += 1\nprint('%d columns were label encoded' % ct)\nprint ('shape of train data', app_train.shape)\nprint ('shape of test data', app_test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a110b174f6259f6ae20c911393b6fad7ed3c3d3f",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "app_train = pd.get_dummies(app_train)\napp_test = pd.get_dummies(app_test)\nprint ('shape of train data', app_train.shape)\nprint ('shape of test data', app_test.shape)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "34491d77ddd210d8f53b4a3b82dbae4abe6ad19b",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_labels = app_train['TARGET']\napp_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\napp_train['TARGET'] = train_labels\nprint ('shape of train data', app_train.shape)\nprint ('shape of test data', app_test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d8a2fd98dda3a2570562d3d28d146a7b4d5bd743",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#app_train ['DAYS_EMPLOYED'].plot.hist()\n%matplotlib inline\n#app_train ['DAYS_EMPLOYED'].plot.hist()\nanom = app_train[app_train['DAYS_EMPLOYED'] > 10000]\nanom['TARGET'].where(anom['TARGET'] < 0.8).plot.hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8bf5c4a405cd3c3871fa63b46426612ae0347876",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\nprint(app_train[\"DAYS_EMPLOYED\"].max())\napp_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\napp_train['DAYS_EMPLOYED'].plot.hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0ca46311164c31ff1dd814b1e637900869c4c14b",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\napp_test['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\nprint('There are ', app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), \" anomalies in test set\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2b476437110fc8517072b5d31a0a47e4ea2aa609",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "correlations = app_train.corrwith(app_train['TARGET']).sort_values()\nprint(correlations.head(10))\nprint(correlations.tail(10))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4ecd4692e5a5f3d8b46d2291ba0640a012a70e3e",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "app_train[\"EXT_SOURCE_1\"].plot.hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6eafa8c78bb4ef38d77d3328c9991c2cc8cb6ef3",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "app_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\napp_train['DAYS_BIRTH'].corr(app_train['TARGET'])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "59668364acbf5451c600291fcb44643a502a75f0",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import seaborn as sns\nsns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH']/365, label = 'target = 0')\nsns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH']/365, label = 'target = 1')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "286ffbf5c3ec2c268c3c966e10ec0e6dd1592a15",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "age_data = app_train[['TARGET', 'DAYS_BIRTH']]\nage_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365\nage_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins = np.linspace(20, 70, num = 11))\nage_data.head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d89e8316ff14832f212ef74320689eaf44310936",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "age_groups = age_data.groupby('YEARS_BINNED').mean()\nage_groups.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f841232e5d5b3cad853b06506b83ab3bb7344e10",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nplt.figure(figsize = (8,8))\nimport matplotlib.pyplot as plt\nplt.bar(age_groups.index.astype(str), 100 * age_groups['TARGET'])\nplt.xticks(rotation = 75); plt.xlabel('Age Group (years)'); plt.ylabel('Failure to Repay (%)')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ae3e97fe19652fc8801168e884507c96366f84d3",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "ext_data = app_train[['TARGET', 'EXT_SOURCE_1','EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\next_data_corr = ext_data.corr()\next_data_corr",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ca552e2228f5f92f318a35452cf110df834f67b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize = (8,8))\nsns.heatmap(ext_data_corr, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b74e7e23c6684f0655ab25bf30b86aab7202a4a6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "poly_features_train = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\npoly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(strategy = 'median')\n\ntrain_target = poly_features_train['TARGET']\n\npoly_features_train = poly_features_train.drop(columns = ['TARGET'])\n\npoly_features_train = imputer.fit_transform(poly_features_train)\npoly_features_test = imputer.fit_transform(poly_features_test)\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly_transformer = PolynomialFeatures(degree = 3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53944f1d78ee96b9760f2cc55e85306ef37444ab",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "poly_transformer.fit(poly_features_train)\n\npoly_features_train = poly_transformer.transform(poly_features_train)\npoly_features_test = poly_transformer.transform(poly_features_test)\n\npoly_transformer.get_feature_names(input_features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de688128905e2a48657dcaa91a80adcb426acd85",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "poly_features_test = pd.DataFrame(poly_features_test, \n                                  columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n                                                                                'EXT_SOURCE_3', 'DAYS_BIRTH']))\npoly_features_train = pd.DataFrame(poly_features_train, \n                                  columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n                                                                                'EXT_SOURCE_3', 'DAYS_BIRTH']))\n\npoly_features_train['SK_ID_CURR'] = app_train['SK_ID_CURR']\napp_train_poly = app_train.merge(poly_features_train, on = 'SK_ID_CURR', how = 'left')\n\n# Merge polnomial features into testing dataframe\npoly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\napp_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')\n\n# Align the dataframes\napp_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)\n\n# Print out the new shapes\nprint('Training data with polynomial features shape: ', app_train_poly.shape)\nprint('Testing data with polynomial features shape:  ', app_test_poly.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1d8c455c03fa8ede0de12dc781fd38cd7f53d173"
      },
      "cell_type": "code",
      "source": "app_train_domain = app_train.copy()\napp_test_domain = app_test.copy()\n\napp_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\napp_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\napp_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\napp_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "760ad19dc9f2561019c836a2d8b76e3e752a768d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler, Imputer\n\ntrain = app_train.drop(columns = ['TARGET'])\ntest = app_test.copy()\n\nimputer = Imputer(strategy='median')\n\nscaler = MinMaxScaler(feature_range = (0,1))\n\nimputer.fit(train)\n\ntrain = imputer.transform(train)\ntest = imputer.transform(test)\n\nscaler.fit(train)\n\ntrain = scaler.transform(train)\ntest = scaler.transform(test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ed1653d8f4472eebdbf6d7c3da8dc7e6af9fb13e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression(C = 0.0001)\n\nlog_reg.fit(train, train_labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "5547050212d164149b5134d1f521aef8c2df076e"
      },
      "cell_type": "code",
      "source": "log_reg_pred = log_reg.predict_proba(test)[:, 1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd15684af6009f031d65b773b005c2982e3a4196",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\nsubmit.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1383a30130cd23e1513b8ab74d89ddbcae1cac64",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submit.to_csv('log_reg_baseline.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "c1f4dfd2fbeeaf2554f9734365cf5a9e18012939"
      },
      "cell_type": "code",
      "source": "from sklearn.ensmble import RandomForestClassifier\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f986588faab0fdd399200bb89a99d5c3967c0edf"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}